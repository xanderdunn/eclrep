{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Set seeds\n",
    "tf.set_random_seed(42)\n",
    "np.random.seed(42)\n",
    "   \n",
    "# Import the mLSTM babbler model\n",
    "from unirep import babbler1900 as babbler\n",
    "    \n",
    "# Where model weights are stored.\n",
    "MODEL_WEIGHT_PATH = \"./data/1900_weights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "batch_size = 12\n",
    "model = babbler(batch_size=batch_size, model_path=MODEL_WEIGHT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading existing output file...\n",
      "Got 3580 existing data points\n",
      "Processing data from ssm2_stability_scores.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee9e7fef6414954a68d95cad568f1d3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n",
      "Appending 20 points...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "path = \"./data/stability_data\"\n",
    "output_path = os.path.join(path, \"stability_with_unirep_fusion.hdf\")\n",
    "\n",
    "existing_output = pd.DataFrame(columns=[\"name\", \"sequence\", \"stability\"])\n",
    "if os.path.isfile(output_path):\n",
    "    print(\"Reading existing output file...\")\n",
    "    existing_output = pd.read_hdf(output_path, key=\"ids\")\n",
    "    print(\"Got {} existing data points\".format(existing_output.shape[0]))\n",
    "    duplicates = existing_output.duplicated(subset=[\"sequence\"])\n",
    "    assert True not in duplicates.values\n",
    "\n",
    "new_ids_output = pd.DataFrame(columns=[\"name\", \"sequence\", \"stability\"])\n",
    "new_reps_output = pd.DataFrame(columns=list(range(0, 5700)))\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        print(\"Processing data from {}\".format(filename))\n",
    "        df = pd.read_table(os.path.join(path, filename))\n",
    "        for index, row in tqdm(df.iterrows(), total=df.shape[0]): # TODO: Parallelize this\n",
    "            if index != 0 and index % 20 == 0:\n",
    "                assert new_ids_output.shape[0] == new_reps_output.shape[0]\n",
    "                if new_ids_output.shape[0] > 0:\n",
    "                    print(\"Appending {} points...\".format(new_ids_output.shape[0]))\n",
    "                    new_ids_output.to_hdf(output_path, index=False, mode=\"a\", key=\"ids\", format=\"table\", append=True)\n",
    "                    new_ids_output = pd.DataFrame(columns=[\"name\", \"sequence\", \"stability\"])\n",
    "                    new_reps_output.to_hdf(output_path, index=False, mode=\"a\", key=\"reps\", format=\"table\", append=True)\n",
    "                    new_reps_output = pd.DataFrame(columns=list(range(0, 5700)))\n",
    "            # If there is no existing data or the existing data already contains this sequence, ignore it\n",
    "            if existing_output.empty or not row[\"sequence\"] in existing_output[\"sequence\"].values:\n",
    "                if model.is_valid_seq(row[\"sequence\"], max_len=500):\n",
    "                    unirep_fusion = model.get_rep(row[\"sequence\"])\n",
    "                    unirep_fusion = np.concatenate((unirep_fusion[0], unirep_fusion[1], unirep_fusion[2]))\n",
    "                    if \"consensus_stability_score\" in df.columns:\n",
    "                        stability_score = row[\"consensus_stability_score\"]\n",
    "                    else:\n",
    "                        stability_score = row[\"stabilityscore\"]\n",
    "                    new_ids_output.loc[len(new_ids_output)]=[row[\"name\"], row[\"sequence\"], stability_score]\n",
    "                    new_reps_output.loc[len(new_reps_output)]=unirep_fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = pd.read_hdf(output_path, key=\"ids\")\n",
    "print(\"{} points in ids\".format(ids.shape[0]))\n",
    "reps = pd.read_hdf(output_path, key=\"reps\")\n",
    "print(\"{} points in reps\".format(reps.shape[0]))\n",
    "print(reps.iloc[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
